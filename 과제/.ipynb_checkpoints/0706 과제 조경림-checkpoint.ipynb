{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adcd16d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발신제한\n"
     ]
    }
   ],
   "source": [
    "# Q1. 네이버영화 랭킹 가져와서 첫번째 영화제목을 출력하세요.\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "a = soup.select_one('td.title > div.tit3 > a')\n",
    "# print(a.text)\n",
    "print(a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcfcd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발신제한\n",
      "랑종\n",
      "인 더 하이츠\n",
      "블랙 위도우\n",
      "미드나이트\n",
      "크루엘라\n",
      "콰이어트 플레이스 2\n",
      "킬러의 보디가드 2\n",
      "제8일의 밤\n",
      "루카\n",
      "투모로우 워\n",
      "체르노빌 1986\n",
      "빛나는 순간\n",
      "괴기맨숀\n",
      "기담\n",
      "싱크홀\n",
      "열아홉\n",
      "아이스 로드\n",
      "컨저링 3: 악마가 시켰다\n",
      "모가디슈\n",
      "인질\n",
      "다크 앤드 위키드\n",
      "이보다 더 좋을 순 없다\n",
      "분노의 질주: 더 얼티메이트\n",
      "셔터\n",
      "미션 임파서블: 루벤\n",
      "캐시트럭\n",
      "더 퍼지: 포에버\n",
      "이스케이프 룸 2: 노 웨이 아웃\n",
      "메이드 인 루프탑\n",
      "극장판 귀멸의 칼날: 무한열차편\n",
      "이번엔 잘 되겠지\n",
      "콰이어트 플레이스\n",
      "방법: 재차의\n",
      "뱅퀴시\n",
      "보스 베이비 2\n",
      "여고괴담 여섯번째 이야기 : 모교\n",
      "오필리아\n",
      "더 수어사이드 스쿼드\n",
      "웬디\n",
      "트립 투 그리스\n",
      "곡성(哭聲)\n",
      "스페이스 잼: 새로운 시대\n",
      "한산: 용의 출현\n",
      "우리는 매일매일\n",
      "아이윌 송\n",
      "북샵\n",
      "블라이스 스피릿\n",
      "시카다 3301\n",
      "꽃다발 같은 사랑을 했다\n"
     ]
    }
   ],
   "source": [
    "# Q2. 네이버 영화 랭킹 가져와서 전체 영화제목을 출력하세요.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "a = soup.select('td.title > div.tit3 >a')\n",
    "\n",
    "for i in a:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6694fd",
   "metadata": {},
   "source": [
    "Q3.\"http://api.aoikujira.com/time/get.php \" 으로 부터 아래와 같이 출력하세요.  \n",
    "2020/08/02 08:06:45  \n",
    "b'2020/08/02 08:06:45'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62823fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/07/07 09:31:14\n",
      "b'2021/07/07 09:31:14'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('http://api.aoikujira.com/time/get.php').text\n",
    "print(response)\n",
    "\n",
    "import urllib\n",
    "response2 = urllib.request.urlopen('http://api.aoikujira.com/time/get.php')\n",
    "byte = response2.read()\n",
    "print(byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb6373",
   "metadata": {},
   "source": [
    "Q4.\"http://naver.com \"에서 header의 요소들을 가져와서 for문으로 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8f56365",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server\n",
      "Date\n",
      "Content-Type\n",
      "Transfer-Encoding\n",
      "Connection\n",
      "Set-Cookie\n",
      "Cache-Control\n",
      "Pragma\n",
      "P3P\n",
      "X-Frame-Options\n",
      "X-XSS-Protection\n",
      "Content-Encoding\n",
      "Strict-Transport-Security\n",
      "Referrer-Policy\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "req = requests.get('http://naver.com')\n",
    "html = req.text\n",
    "header = req.headers\n",
    "\n",
    "for i in header:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58f826",
   "metadata": {},
   "source": [
    "Q5. 아래를 예외 처리하세요.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accd5730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URL 'naver.com': No schema supplied. Perhaps you meant http://naver.com?\n"
     ]
    }
   ],
   "source": [
    "import requests as rq  \n",
    "\n",
    "try: \n",
    "    url = \"naver.com\"  \n",
    "    res = rq.get(url)  \n",
    "    print(res.text) \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "19f2ccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>파이썬 크롤러 책1</p>, <p>전문서적</p>, <p id=\"d\">정보 문화사</p>]\n",
      "[<p id=\"d\">정보 문화사</p>]\n",
      "[<p>파이썬 크롤러 책1</p>, <p>전문서적</p>]\n"
     ]
    }
   ],
   "source": [
    "#Q6. 아래 html에서 다음을 출력하세요.\n",
    "#[<p>파이썬 크롤러 책1</p>, <p>전문서적</p>, <p id=\"d\">정보 문화사</p>]  \n",
    "#[<p id=\"d\">정보문화사</p>]\n",
    "#[<p>파이썬 크롤러 책1</p>, <p>전문서적</p>]  \n",
    "html =\"\"\"  \n",
    "<!DOCTYPE html>  \n",
    "<html lang=\"en\">  \n",
    "<head>  \n",
    "    <meta charset=\"UTF-8\">  \n",
    "    <title>Title</title>\n",
    "</head>\n",
    "<body>\n",
    "    <p>파이썬 크롤러 책1</p>\n",
    "    <p>전문서적</p>\n",
    "    <p id='d'>정보 문화사</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(html, 'html.parser')\n",
    "body = soup.body\n",
    "body1 = list(body)\n",
    "\n",
    "print(body.select('p'))\n",
    "print(body.select('p#d'))\n",
    "# print(a.find_all('p',id=True))\n",
    "print(body.select('p')[0:2])\n",
    "# print(a.find_all('p',id=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b25f00ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f886b5e04781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlist2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"body>p#d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mlist2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list1' is not defined"
     ]
    }
   ],
   "source": [
    "html =\"\"\"  \n",
    "<!DOCTYPE html>  \n",
    "<html lang=\"en\">  \n",
    "<head>  \n",
    "    <meta charset=\"UTF-8\">  \n",
    "    <title>Title</title>\n",
    "</head>\n",
    "<body>\n",
    "    <p>파이썬 크롤러 책1</p>\n",
    "    <p>전문서적</p>\n",
    "    <p id='d'>정보 문화사</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "list2=soup.select(\"body>p#d\")\n",
    "list2\n",
    "a=[x for x in list1 if x not in list2]\n",
    "print(a)\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup=BeautifulSoup(html,'html.parser')\n",
    "\n",
    "list1=soup.select(\"body>p\")\n",
    "print(list1)\n",
    "print()\n",
    "    \n",
    "list2=soup.select(\"body>p#d\")\n",
    "list2\n",
    "a=[x for x in list1 if x not in list2]\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b253807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q. 아래와 같이 출력하세요.\n",
    "# <title>Title</title>  \n",
    "# <h2 id=\"target1\">h2 태그</h2>  \n",
    "# <a href=\"/\" id=\"target2\">a 태그</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b59d192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Title</title>\n",
      "Title\n",
      "<h2 id=\"target1\">h2 태그</h2>\n",
      "h2 태그\n",
      "<a href=\"/\" id=\"target2\">a 태그</a>\n",
      "a 태그\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Title</title>            #여기\n",
    "    <style>\n",
    "        #target1{\n",
    "            font-size: 40px;\n",
    "            color: blue;\n",
    "        }\n",
    "        #target2{\n",
    "            font-size: 40px;\n",
    "            color: red;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>h1 태그</h1>\n",
    "    <h2 id=\"target1\">h2 태그</h2>             #여기\n",
    "    <h3>h3 태그</h3>\n",
    "    <a href=\"/\" id=\"target2\">a 태그</a>      #여기\n",
    "</body> \n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(html, 'html.parser')\n",
    "# print(soup.select('title'))\n",
    "# print(soup.select('h2#target1'))\n",
    "# print(soup.select('a'))\n",
    "\n",
    "\n",
    "for i in soup.find_all(['title','h2','a']):\n",
    "    print(i)\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4653d",
   "metadata": {},
   "source": [
    "# Q. 아래 html 문에서 다음과 같이 출력되도록 스크레이핑 하세요.\n",
    "\n",
    "h1 = HTML 기본 구조  \n",
    "li = html5 명시  \n",
    "li = html 태그로 모든 태그를 감싸줌. lang이란 속성을 포함  \n",
    "li = head 태그는 meta, title 이외의 style, script, link와 같은 태그 포함  \n",
    "li = title 태그는 문서의 제목  \n",
    "li = body 태그는 웹페이지의 내용 포함  \n",
    "li = style 태그는 CSS 코드가 포함된는 태그  \n",
    "li = script 태그는 JavaScript 코드를 작성하거나 파일 로드. head 태그 or body 태그 하단 위치  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e0448fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HTML 기본 구조\n",
      "\n",
      "html5 명시\n",
      "html 태그로 모든 태그를 감싸줌. lang이란 속성을 포함\n",
      "head 태그는 meta, title 이외의 style, script, link와 같은 태그 포함\n",
      "title 태그는 문서의 제목\n",
      "body 태그는 웹페이지의 내용 포함\n",
      "style 태그는 CSS 코드가 포함된는 태그\n",
      "script 태그는 JavaScript 코드를 작성하거나 파일 로드. head 태그 or body 태그 하단 위치\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"  \n",
    "<html><body>  \n",
    "<div id=\"meigen\">  \n",
    "  <h1>HTML 기본 구조</h1>  \n",
    "  <ul class=\"items\">  \n",
    "    <li>html5 명시</li>  \n",
    "    <li>html 태그로 모든 태그를 감싸줌. lang이란 속성을 포함</li>  \n",
    "    <li>head 태그는 meta, title 이외의 style, script, link와 같은 태그 포함</li>  \n",
    "    <li>title 태그는 문서의 제목</li>  \n",
    "    <li>body 태그는 웹페이지의 내용 포함</li>  \n",
    "    <li>style 태그는 CSS 코드가 포함된는 태그</li>  \n",
    "    <li>script 태그는 JavaScript 코드를 작성하거나 파일 로드. head 태그 or body 태그 하단 위치</li>  \n",
    "  </ul>  \n",
    "</div>  \n",
    "</body></html>  \n",
    "\"\"\"  \n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(html, 'html.parser')\n",
    "soup = soup.select('div#meigen')\n",
    "for i in soup:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "604680f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = HTML 기본 구조\n",
      "li = html5 명시\n",
      "li = html 태그로 모든 태그를 감싸줌. lang이란 속성을 포함\n",
      "li = head 태그는 meta, title 이외의 style, script, link와 같은 태그 포함\n",
      "li = title 태그는 문서의 제목\n",
      "li = body 태그는 웹페이지의 내용 포함\n",
      "li = style 태그는 CSS 코드가 포함된는 태그\n",
      "li = script 태그는 JavaScript 코드를 작성하거나 파일 로드. head 태그 or body 태그 하단 위치\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"  \n",
    "<html><body>  \n",
    "<div id=\"meigen\">  \n",
    "  <h1>HTML 기본 구조</h1>  \n",
    "  <ul class=\"items\">  \n",
    "    <li>html5 명시</li>  \n",
    "    <li>html 태그로 모든 태그를 감싸줌. lang이란 속성을 포함</li>  \n",
    "    <li>head 태그는 meta, title 이외의 style, script, link와 같은 태그 포함</li>  \n",
    "    <li>title 태그는 문서의 제목</li>  \n",
    "    <li>body 태그는 웹페이지의 내용 포함</li>  \n",
    "    <li>style 태그는 CSS 코드가 포함된는 태그</li>  \n",
    "    <li>script 태그는 JavaScript 코드를 작성하거나 파일 로드. head 태그 or body 태그 하단 위치</li>  \n",
    "  </ul>  \n",
    "</div>  \n",
    "</body></html>  \n",
    "\"\"\"  \n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(html, 'html.parser')\n",
    "soup = soup.find_all(['h1','li'])\n",
    "for i in soup:\n",
    "    print(i.name,'=',i.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32baec00",
   "metadata": {},
   "source": [
    "### Q. 특정 웹사이트를 지정한 후 원하는 크롤링 만들기(최대한 역량 발휘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "55a64b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다산의 마지막 습관\n",
      "반야심경 마음공부\n",
      "동경대전 1\n",
      "동경대전 2\n",
      "요가난다, 영혼의 자서전\n",
      "중국정치사상사\n",
      "나 홀로 읽는 도덕경\n",
      "다산의 마지막 공부\n",
      "진리와 자유의 길\n",
      "불교에 대해 꼭 알아야 할 100가지\n",
      "돈과 운을 부르는 색채 명리학\n",
      "합충변화\n",
      "순암집\n",
      "손자병법\n",
      "피클 일주론 사주명리학의 꽃\n",
      "논어\n",
      "논어\n",
      "우파니샤드\n",
      "인식론평석 : 지각론\n",
      "명리 : 운명을 읽다\n",
      "한국은 하나의 철학이다\n",
      "간편하게 익히고 두고두고 들춰보는 주역 입문 강의\n",
      "한 권으로 읽는 벽암록\n",
      "내 인생의 주역\n",
      "명심보감\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "URL = 'https://www.aladin.co.kr/shop/wbrowse.aspx?CID=51393'\n",
    "req = requests.get(URL).text\n",
    "soup = bs(req, 'html.parser')\n",
    "soup = soup.find_all('a', attrs={'class':'bo3'})\n",
    "for i in soup:\n",
    "    print(i.string)  #list 뽑기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
