{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424ede6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=90bafe761edd3b9cd7804a8997cc4326b1b6e7980e726b3c1cab042770011446\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.9.3 bs4-0.0.1 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# 뷰티풀숩 설치\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73cdcb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ca_da\\anaconda\\envs\\cakd3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_tflow_select             2.3.0                     eigen  \n",
      "absl-py                   0.12.0           py38haa95532_0  \n",
      "aiohttp                   3.7.4            py38h2bbff1b_1  \n",
      "argon2-cffi               20.1.0           py38h2bbff1b_1  \n",
      "astor                     0.8.1            py38haa95532_0  \n",
      "astunparse                1.6.3                      py_0  \n",
      "async-timeout             3.0.1            py38haa95532_0  \n",
      "async_generator           1.10               pyhd3eb1b0_0  \n",
      "attrs                     21.2.0             pyhd3eb1b0_0  \n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \n",
      "beautifulsoup4            4.9.3                    pypi_0    pypi\n",
      "blas                      1.0                         mkl  \n",
      "bleach                    3.3.0              pyhd3eb1b0_0  \n",
      "blinker                   1.4              py38haa95532_0  \n",
      "brotlipy                  0.7.0           py38h2bbff1b_1003  \n",
      "bs4                       0.0.1                    pypi_0    pypi\n",
      "ca-certificates           2021.5.25            haa95532_1  \n",
      "cachetools                4.2.2              pyhd3eb1b0_0  \n",
      "certifi                   2021.5.30        py38haa95532_0  \n",
      "cffi                      1.14.5           py38hcd4344a_0  \n",
      "chardet                   3.0.4           py38haa95532_1003  \n",
      "click                     8.0.1              pyhd3eb1b0_0  \n",
      "colorama                  0.4.4              pyhd3eb1b0_0  \n",
      "coverage                  5.5              py38h2bbff1b_2  \n",
      "cryptography              3.4.7            py38h71e12ea_0  \n",
      "cycler                    0.10.0                   py38_0  \n",
      "cython                    0.29.23          py38hd77b12b_0  \n",
      "decorator                 5.0.9              pyhd3eb1b0_0  \n",
      "defusedxml                0.7.1              pyhd3eb1b0_0  \n",
      "entrypoints               0.3                      py38_0  \n",
      "freetype                  2.10.4               hd328e21_0  \n",
      "gast                      0.4.0                      py_0  \n",
      "google-auth               1.31.0             pyhd3eb1b0_0  \n",
      "google-auth-oauthlib      0.4.4              pyhd3eb1b0_0  \n",
      "google-pasta              0.2.0                      py_0  \n",
      "grpcio                    1.36.1           py38hc60d5dd_1  \n",
      "h5py                      2.10.0           py38h5e291fa_0  \n",
      "hdf5                      1.10.4               h7ebc959_0  \n",
      "icc_rt                    2019.0.0             h0cc432a_1  \n",
      "icu                       58.2                 ha925a31_3  \n",
      "idna                      2.10               pyhd3eb1b0_0  \n",
      "importlib-metadata        3.10.0           py38haa95532_0  \n",
      "importlib_metadata        3.10.0               hd3eb1b0_0  \n",
      "intel-openmp              2021.2.0           haa95532_616  \n",
      "ipykernel                 5.3.4            py38h5ca1d4c_0  \n",
      "ipython                   7.22.0           py38hd4e2768_0  \n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \n",
      "ipywidgets                7.6.3              pyhd3eb1b0_1  \n",
      "jedi                      0.17.0                   py38_0  \n",
      "jinja2                    3.0.0              pyhd3eb1b0_0  \n",
      "joblib                    1.0.1              pyhd3eb1b0_0  \n",
      "jpeg                      9b                   hb83a4c4_2  \n",
      "jsonschema                3.2.0                      py_2  \n",
      "jupyter                   1.0.0                    py38_7  \n",
      "jupyter_client            6.1.12             pyhd3eb1b0_0  \n",
      "jupyter_console           6.4.0              pyhd3eb1b0_0  \n",
      "jupyter_core              4.7.1            py38haa95532_0  \n",
      "jupyterlab_pygments       0.1.2                      py_0  \n",
      "jupyterlab_widgets        1.0.0              pyhd3eb1b0_1  \n",
      "keras                     2.4.3                         0  \n",
      "keras-applications        1.0.8                      py_1  \n",
      "keras-base                2.4.3                      py_0  \n",
      "keras-preprocessing       1.1.2              pyhd3eb1b0_0  \n",
      "kiwisolver                1.3.1            py38hd77b12b_0  \n",
      "libpng                    1.6.37               h2a8f88b_0  \n",
      "libprotobuf               3.14.0               h23ce68f_0  \n",
      "libsodium                 1.0.18               h62dcd97_0  \n",
      "libtiff                   4.2.0                hd0e1b90_0  \n",
      "lz4-c                     1.9.3                h2bbff1b_0  \n",
      "m2w64-gcc-libgfortran     5.3.0                         6  \n",
      "m2w64-gcc-libs            5.3.0                         7  \n",
      "m2w64-gcc-libs-core       5.3.0                         7  \n",
      "m2w64-gmp                 6.1.0                         2  \n",
      "m2w64-libwinpthread-git   5.0.0.4634.697f757               2  \n",
      "markdown                  3.3.4            py38haa95532_0  \n",
      "markupsafe                2.0.1            py38h2bbff1b_0  \n",
      "matplotlib                3.3.4            py38haa95532_0  \n",
      "matplotlib-base           3.3.4            py38h49ac443_0  \n",
      "mistune                   0.8.4           py38he774522_1000  \n",
      "mkl                       2021.2.0           haa95532_296  \n",
      "mkl-service               2.3.0            py38h2bbff1b_1  \n",
      "mkl_fft                   1.3.0            py38h277e83a_2  \n",
      "mkl_random                1.2.1            py38hf11a4ad_2  \n",
      "msys2-conda-epoch         20160418                      1  \n",
      "multidict                 5.1.0            py38h2bbff1b_2  \n",
      "nbclient                  0.5.3              pyhd3eb1b0_0  \n",
      "nbconvert                 6.0.7                    py38_0  \n",
      "nbformat                  5.1.3              pyhd3eb1b0_0  \n",
      "nest-asyncio              1.5.1              pyhd3eb1b0_0  \n",
      "notebook                  6.4.0            py38haa95532_0  \n",
      "numpy                     1.20.2           py38ha4e8547_0  \n",
      "numpy-base                1.20.2           py38hc2deb75_0  \n",
      "oauthlib                  3.1.0                      py_0  \n",
      "olefile                   0.46                       py_0  \n",
      "openssl                   1.1.1k               h2bbff1b_0  \n",
      "opt_einsum                3.3.0              pyhd3eb1b0_1  \n",
      "packaging                 20.9               pyhd3eb1b0_0  \n",
      "pandas                    1.2.4            py38hd77b12b_0  \n",
      "pandoc                    2.12                 haa95532_0  \n",
      "pandocfilters             1.4.3            py38haa95532_1  \n",
      "parso                     0.8.2              pyhd3eb1b0_0  \n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
      "pillow                    8.2.0            py38h4fa10fc_0  \n",
      "pip                       21.1.2           py38haa95532_0  \n",
      "prometheus_client         0.11.0             pyhd3eb1b0_0  \n",
      "prompt-toolkit            3.0.17             pyh06a4308_0  \n",
      "prompt_toolkit            3.0.17               hd3eb1b0_0  \n",
      "protobuf                  3.14.0           py38hd77b12b_1  \n",
      "pyasn1                    0.4.8                      py_0  \n",
      "pyasn1-modules            0.2.8                      py_0  \n",
      "pycparser                 2.20                       py_2  \n",
      "pygments                  2.9.0              pyhd3eb1b0_0  \n",
      "pyjwt                     1.7.1                    py38_0  \n",
      "pyopenssl                 20.0.1             pyhd3eb1b0_1  \n",
      "pyparsing                 2.4.7              pyhd3eb1b0_0  \n",
      "pyqt                      5.9.2            py38ha925a31_4  \n",
      "pyreadline                2.1                      py38_1  \n",
      "pyrsistent                0.17.3           py38he774522_0  \n",
      "pysocks                   1.7.1            py38haa95532_0  \n",
      "python                    3.8.10               hdbf39b2_7  \n",
      "python-dateutil           2.8.1              pyhd3eb1b0_0  \n",
      "pytz                      2021.1             pyhd3eb1b0_0  \n",
      "pywin32                   227              py38he774522_1  \n",
      "pywinpty                  0.5.7                    py38_0  \n",
      "pyyaml                    5.4.1            py38h2bbff1b_1  \n",
      "pyzmq                     20.0.0           py38hd77b12b_1  \n",
      "qt                        5.9.7            vc14h73c81de_0  \n",
      "qtconsole                 5.1.0              pyhd3eb1b0_0  \n",
      "qtpy                      1.9.0                      py_0  \n",
      "requests                  2.25.1             pyhd3eb1b0_0  \n",
      "requests-oauthlib         1.3.0                      py_0  \n",
      "rsa                       4.7.2              pyhd3eb1b0_1  \n",
      "scikit-learn              0.24.2           py38hf11a4ad_1  \n",
      "scipy                     1.6.2            py38h66253e8_1  \n",
      "seaborn                   0.11.1             pyhd3eb1b0_0  \n",
      "send2trash                1.5.0              pyhd3eb1b0_1  \n",
      "setuptools                52.0.0           py38haa95532_0  \n",
      "sip                       4.19.13          py38ha925a31_0  \n",
      "six                       1.16.0             pyhd3eb1b0_0  \n",
      "soupsieve                 2.2.1                    pypi_0    pypi\n",
      "sqlite                    3.35.4               h2bbff1b_0  \n",
      "tensorboard               2.4.0              pyhc547734_0  \n",
      "tensorboard-plugin-wit    1.6.0                      py_0  \n",
      "tensorflow                2.3.0           mkl_py38h8c0d9a2_0  \n",
      "tensorflow-base           2.3.0           eigen_py38h75a453f_0  \n",
      "tensorflow-estimator      2.5.0              pyh7b7c402_0  \n",
      "termcolor                 1.1.0            py38haa95532_1  \n",
      "terminado                 0.9.4            py38haa95532_0  \n",
      "testpath                  0.4.4              pyhd3eb1b0_0  \n",
      "threadpoolctl             2.1.0              pyh5ca1d4c_0  \n",
      "tk                        8.6.10               he774522_0  \n",
      "tornado                   6.1              py38h2bbff1b_0  \n",
      "traitlets                 5.0.5              pyhd3eb1b0_0  \n",
      "typing-extensions         3.7.4.3              hd3eb1b0_0  \n",
      "typing_extensions         3.7.4.3            pyh06a4308_0  \n",
      "urllib3                   1.26.4             pyhd3eb1b0_0  \n",
      "vc                        14.2                 h21ff451_1  \n",
      "vs2015_runtime            14.27.29016          h5e58377_2  \n",
      "wcwidth                   0.2.5                      py_0  \n",
      "webencodings              0.5.1                    py38_1  \n",
      "werkzeug                  1.0.1              pyhd3eb1b0_0  \n",
      "wheel                     0.36.2             pyhd3eb1b0_0  \n",
      "widgetsnbextension        3.5.1                    py38_0  \n",
      "win_inet_pton             1.1.0            py38haa95532_0  \n",
      "wincertstore              0.2                      py38_0  \n",
      "winpty                    0.4.3                         4  \n",
      "wrapt                     1.12.1           py38he774522_1  \n",
      "xz                        5.2.5                h62dcd97_0  \n",
      "yaml                      0.2.5                he774522_0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yarl                      1.6.3            py38h2bbff1b_0  \n",
      "zeromq                    4.3.3                ha925a31_3  \n",
      "zipp                      3.4.1              pyhd3eb1b0_0  \n",
      "zlib                      1.2.11               h62dcd97_4  \n",
      "zstd                      1.4.9                h19a0ad4_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d4370",
   "metadata": {},
   "source": [
    "BeautifulSoup 모듈\n",
    "- 홈페이지 내 데이터를 쉽게 추출할 수 있게 해주는 파이썬 외부 라이브러리\n",
    "- 웹 문서 내 많은 HTML 태그들을 parser를 활용해 사용하기 편한 파이썬 객체로 만들어 제공\n",
    "- 웹문서 구조를 알고 있다면 편하게 데이터를 뽑아 활용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b9957b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html>\n",
      "<head>\n",
      "</head>\n",
      "<body>\n",
      "<h1>스크레이핑이란?</h1>\n",
      "<p>웹 페이지를 분석하는 것</p>\n",
      "<p>원하는 부분을 추출하는 것</p>\n",
      "<p>원하는??? 부분을 추출하는 것</p>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "<h1>스크레이핑이란?</h1>\n",
      "스크레이핑이란?\n",
      "스크레이핑이란?\n",
      "웹 페이지를 분석하는 것\n",
      "원하는 부분을 추출하는 것\n",
      "원하는??? 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# 기본적인 html 문서 구조\n",
    "html =\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "</head>\n",
    "<body>\n",
    "   <h1>스크레이핑이란?</h1>\n",
    "   <p>웹 페이지를 분석하는 것</p>\n",
    "   <p>원하는 부분을 추출하는 것</p>\n",
    "   <p>원하는??? 부분을 추출하는 것</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# parser종류는 html.parser,lxml,html5lib가 있음\n",
    "print(soup)\n",
    "h1 = soup.body.h1\n",
    "print(h1)\n",
    "print(h1.string)\n",
    "print(h1.text)\n",
    "p1 = soup.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "p3 = p2.next_sibling.next_sibling\n",
    "print(p1.string)\n",
    "print(p2.string)\n",
    "print(p3.string)\n",
    "\n",
    "# html의 DOM이 뭔지 찾아보고 정리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028bb3f",
   "metadata": {},
   "source": [
    "find() : HTML 태그에 대한 첫번째 정보를 가져옴\n",
    "- find(속성='값') : HTML 해당 속성과 일치하는 값에 대한 첫 번째 정보를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d46c595a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크레이핑이란?\n",
      "웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "# id로 요소를 찾는 방법\n",
    "from bs4 import BeautifulSoup\n",
    "html =\"\"\"\n",
    "<body>\n",
    "   <h1 id='title'>스크레이핑이란?</h1>\n",
    "   <p id='body'>웹 페이지를 분석하는 것</p>\n",
    "   <p>원하는 부분을 추출하는 것</p>\n",
    "   <p>원하는??? 부분을 추출하는 것</p>\n",
    "</body>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "title = soup.find(id='title')\n",
    "body = soup.find(id='body')\n",
    "\n",
    "print(title.string)\n",
    "print(body.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4185e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver > http://www.naver.com\n",
      "daum > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 요소 추출  -> html 태그 정리해서 보기   ,질문하기\n",
    "# https://pridiot.tistory.com/6\n",
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "   <ul>\n",
    "     <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "     <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "    </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = soup.find_all('a')\n",
    "for a in links:\n",
    "    href = a.attrs['href']  #속성 알려줌\n",
    "    text = a.string\n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11f47a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n",
      "○ (강수) 9일(금)은 전국에 비가 오겠고, 제주도는 11일(일)까지 이어지겠습니다. <br />          10일(토)~11일(일) 오후에 전국(강원영동 제외)에 비가 오겠고, 12일(월) 오후에 수도권과 강원영서, 충청권에, 13일(화) 오전 수도권과 강원영서에 비가 오겠습니다.<br />○ (기온) 이번 예보기간 아침 기온은 21~25도, 낮 기온은 27~33도로 어제(5일, 아침최저기온 19~23도, 낮최고기온 23~30도)보다 높겠습니다.<br />○ (주말전망) 10일(토)~11일(일)은 전국이 구름많고 오후에 비가 오겠습니다. 아침 기온은 21~24도, 낮 기온은 27~32도가 되겠습니다.<br /> <br />* 9일까지 오랜기간 비가 이어지면서 지반이 약해져 축대붕괴, 산사태 등의 피해가 우려되니, 사전에 철저히 대비하기 바랍니다.<br />* 이번 예보기간 동안 북태평양고기압의 확장 정도와 정체전선의 위치에 따라 강수 변동성이 크겠으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "# urlopen과 beautifulsoup의 조합\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "URL = 'http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "response = urllib.request.urlopen(URL)\n",
    "content = response.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "find1 = soup.find('title')  #find는 처음걸 찾는다.\n",
    "find2 = soup.find('wf')\n",
    "print(find1.string)\n",
    "print(find2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f6253",
   "metadata": {},
   "source": [
    "find_all(): \n",
    "- HTML의 해당 태그에 대한 모든 정보를 리스트 형식으로 가져옴. limit 옵션으로 개수 지정 가능\n",
    "- CSS 속성으로 필터링(class_(생략가능)로 클래스를 직접 사용. 혹은 attrs에서 속성=값으로 필터링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5772e60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"link_set\" data-clk=\"top.mkhome\" href=\"https://help.naver.com/support/welcomePage/guide.help\" id=\"NM_set_home_btn\">네이버를 시작페이지로</a>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "req = requests.get('https://www.naver.com')\n",
    "html = req.text\n",
    "# print(html)\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "result = soup.find_all('a', class_='link_set')\n",
    "# a태그에서 속성이 클래스인걸 찾은 것. 그냥 a만하면 엄청 나옴.\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "84c50d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>기상청 육상 중기예보</title>\n",
      "title\n",
      "기상청 육상 중기예보\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-3e5bd68eac67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#공백이나옴. []는 속성을 물어보는 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.name)\n",
    "print(soup.title.string)\n",
    "print(soup.img)\n",
    "print(soup.img['alt']) #공백이나옴. []는 속성을 물어보는 것\n",
    "print(soup.a)\n",
    "print(soup.a['href'])\n",
    "print(soup.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e9b3059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>, <a href=\"#themecast\"><span>주제별캐스트 바로가기</span></a>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('a', limit=2)) #a태그를 갯수를 정해서 나오게 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec0e6acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('a')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14e28b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div id=\"u_skip\"> <a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a> <a href=\"#themecast\"><span>주제별캐스트 바로가기</span></a> <a href=\"#timesquare\"><span>타임스퀘어 바로가기</span></a> <a href=\"#shopcast\"><span>쇼핑캐스트 바로가기</span></a> <a href=\"#account\"><span>로그인 바로가기</span></a> </div>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('div', id='u_skip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0a383d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"blind\">NAVER whale</span>, <span class=\"blind\">네이버</span>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('span',class_='blind', limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e707499f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"blind\">NAVER whale</span>, <span class=\"blind\">네이버</span>]\n"
     ]
    }
   ],
   "source": [
    "# dictionary type\n",
    "print(soup.find_all('span',attrs={'class':'blind'}, limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2616b4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"item\">추첨 @13@.</span>, <span class=\"item\">지급기한 1년</span>, <span class=\"item\"><i class=\"imsc ico_arr\"></i>@8@(@9@%)</span>, <span class=\"item\">@7@, @message@</span>, <span class=\"item\">@5@</span>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('span',attrs={'class':'blind','class':'item'})) \n",
    "# 틀림, 아래아래 셀 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e3736586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['네이버']\n",
      "['네이버', '네이버를 시작페이지로', '쥬니어네이버', '네이버뉴스', '언론사가 직접 편집한 뉴스들을 네이버 홈에서 바로 보실 수 있습니다.', \"네이버 '개인정보 처리방침' 변경에 대한 안내 말씀드립니다.\", '네이버 개발자 센터', '네이버 D2', '네이버 D2SF', '네이버 랩스', '네이버 정책 및 약관', '네이버 정책']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(soup.find_all(string='네이버'))\n",
    "print(soup.find_all(string=re.compile('네이버')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e47b2470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"blind\">NAVER whale</span>,\n",
       " <span class=\"blind\">네이버</span>,\n",
       " <span class=\"blind\">쥬니어네이버</span>,\n",
       " <span class=\"blind\">해피빈</span>,\n",
       " <span class=\"blind\">검색</span>,\n",
       " <span class=\"blind\">한글 입력기</span>,\n",
       " <span class=\"blind\">자동완성 레이어</span>,\n",
       " <span class=\"item\">추첨 @13@.</span>,\n",
       " <span class=\"item\">지급기한 1년</span>,\n",
       " <span class=\"item\"><i class=\"imsc ico_arr\"></i>@8@(@9@%)</span>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span',attrs={'class':['blind', 'item']}, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f2aeb9",
   "metadata": {},
   "source": [
    "select_one(), select()\n",
    "- CSS 선택자를 활용하여 원하는 정보를 가져옴(태그를 검색하는 find, find_all과 비슷함)\n",
    "- class는 .으로 id는 #으로 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aaf0c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위키북스 도서\n",
      "유니티 게임 이펙트 입문\n",
      "스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "html= \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "h1 = soup.select_one('div#meigen > h1').string #하나만 선택\n",
    "print(h1)\n",
    "li_list = soup.select('div#meigen > ul.items > li')\n",
    "# select는 여러개선택, 출력하려면 여러개여서 for문 써줘야함.\n",
    "for li in li_list:\n",
    "    print(li.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a893e233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-4f851539e7ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mspan1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div#wrap > div#container > div.market_include > div.market_data > div.market1 > div.data >ul.data_1st> div.value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspan1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'string'"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "span1 = soup.select_one('div#wrap > div#container > div.market_include > div.market_data > div.market1 > div.data >ul.data_1st> div.value').string\n",
    "print(span1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "53bbfe3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,132.00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "response = requests.get(url)\n",
    "content = response.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "span1 = soup.select_one('span.value')\n",
    "print(span1.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9cbc652f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,132.10\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://finance.naver.com/marketindex/'\n",
    "response = requests.get(URL)\n",
    "text = response.text\n",
    "soup = BeautifulSoup(text,'html.parser')\n",
    "rate1 = soup.select_one('span.value')\n",
    "print(rate1.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c3f0bc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레몬\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "fp = open('fruits-vegetables.html', encoding='utf8')\n",
    "soup = BeautifulSoup(fp, 'html.parser')\n",
    "print(soup.select_one('li.yellow').string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9ab3e303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<body>\n",
       "<div id=\"main-goods\" role=\"page\">\n",
       "<h1>과일과 야채</h1>\n",
       "<ul id=\"fr-list\">\n",
       "<li class=\"red green\" data-lo=\"ko\">사과</li>\n",
       "<li class=\"purple\" data-lo=\"us\">포도</li>\n",
       "<li class=\"yellow\" data-lo=\"us\">레몬</li>\n",
       "<li class=\"yellow\" data-lo=\"ko\">오렌지</li>\n",
       "</ul>\n",
       "<ul id=\"ve-list\">\n",
       "<li class=\"white green\" data-lo=\"ko\">무</li>\n",
       "<li class=\"red green\" data-lo=\"us\">파프리카</li>\n",
       "<li class=\"black\" data-lo=\"ko\">가지</li>\n",
       "<li class=\"black\" data-lo=\"us\">아보카도</li>\n",
       "<li class=\"white\" data-lo=\"cn\">연근</li>\n",
       "</ul>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "fp = open('fruits-vegetables.html', encoding='utf8')\n",
    "soup = BeautifulSoup(fp, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "22619711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레몬\n",
      "오렌지\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "fp = open('fruits-vegetables.html',encoding='utf8')\n",
    "soup = bs(fp,'html.parser')\n",
    "n_li = soup.select('ul#fr-list > li.yellow')\n",
    "for i in n_li:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1d3edbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과\n",
      "무\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사과'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "fp = open('fruits-vegetables.html',encoding='utf8')\n",
    "soup = bs(fp,'html.parser')\n",
    "print(soup.select_one('ul#fr-list > li[data-lo=\"ko\"]').string)\n",
    "print(soup.select_one('#ve-list > li:nth-of-type(1)').string)\n",
    "n_li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ec1a4eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cond' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-8fb2f0bdd518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'li'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'data-lo'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'us'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ve-list\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"li\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cond' is not defined"
     ]
    }
   ],
   "source": [
    "# 서로 다른 방법으로 아보카도 출력하기\n",
    "from bs4 import BeautifulSoup as bs\n",
    "fp = open('fruits-vegetables.html',encoding='utf8')\n",
    "soup = bs(fp,'html.parser')\n",
    "print(soup.select_one('ul#ve-list > li:nth-of-type(4)').string)\n",
    "print(soup.select('ul#ve-list > li.black')[1].string)\n",
    "print(soup.select('ul#ve-list > li[data-lo=\"us\"]')[1].string)\n",
    "print(soup.find_all('li',attrs={'class':'black', 'data-lo': 'us'})[0].string)\n",
    "print(soup.find_all('li', class_='black')[1].string)\n",
    "print(soup.find(attrs={'class':'black','data-lo':'us'}).string)\n",
    "print(soup.find(id=\"ve-list\").find(\"li\",cond).string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "88774ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://example.com/funa\">fuga*<li>\n",
      "<li><a href=\"https://example.com/foo\">foo*<li>\n",
      "<li><a href=\"http://example.com/aaa\">aaa*<li>\n",
      "</li></a></li></li></a></li></li></a>, <a href=\"https://example.com/foo\">foo*<li>\n",
      "<li><a href=\"http://example.com/aaa\">aaa*<li>\n",
      "</li></a></li></li></a>]\n",
      "https://example.com/funa\n",
      "https://example.com/foo\n"
     ]
    }
   ],
   "source": [
    "# 정규표현식과 BeautifulSoup을 이용하여 https가 포함된 url만 출력하세요.\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "html = \"\"\"\n",
    "<ul>\n",
    "  <li><a href=\"hoge.html\">hoge</li>\n",
    "  <li><a href=\"https://example.com/funa\">fuga*<li>\n",
    "  <li><a href=\"https://example.com/foo\">foo*<li> \n",
    "  <li><a href=\"http://example.com/aaa\">aaa*<li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "p = re.compile('https://.+')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "list_find = soup.find_all('a', attrs={'href': p})\n",
    "print(list_find)\n",
    "for find in list_find:\n",
    "    print(find['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e3dfbac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://example.com/funa\">fuga*<li>\n",
      "<li><a href=\"https://example.com/foo\">foo*<li>\n",
      "<li><a href=\"http://example.com/aaa\">aaa*<li>\n",
      "</li></a></li></li></a></li></li></a>, <a href=\"https://example.com/foo\">foo*<li>\n",
      "<li><a href=\"http://example.com/aaa\">aaa*<li>\n",
      "</li></a></li></li></a>]\n",
      "https://example.com/funa\n",
      "https://example.com/foo\n"
     ]
    }
   ],
   "source": [
    "# 정규표현식과 BeautifulSoup을 이용하여 https가 포함된 url만 출력하세요.\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = \"\"\"\n",
    "<ul>\n",
    "  <li><a href=\"hoge.html\">hoge</li>\n",
    "  <li><a href=\"https://example.com/funa\">fuga*<li>\n",
    "  <li><a href=\"https://example.com/foo\">foo*<li> \n",
    "  <li><a href=\"http://example.com/aaa\">aaa*<li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "list_find = soup.find_all(href = re.compile('^https'))\n",
    "print(list_find)\n",
    "for find in list_find:\n",
    "    print(find['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9aa0b3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.naver.com으로부터\n",
    "# <a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>를 출력하세요\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.naver.com\"\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "soup.select_one('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3da7378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.naver.com\"\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "soup.find_all(href=re.compile('^#newsstand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "983bee73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "발신제한\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 네이버영화 랭킹 가져와서 첫번째 영화제목을 출력하세요.\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "a = soup.select_one('td.title > div.tit3')\n",
    "print(a.text)\n",
    "# print(a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8b80607f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "발신제한\n",
      "\n",
      "\n",
      "인 더 하이츠\n",
      "\n",
      "\n",
      "랑종\n",
      "\n",
      "\n",
      "크루엘라\n",
      "\n",
      "\n",
      "미드나이트\n",
      "\n",
      "\n",
      "콰이어트 플레이스 2\n",
      "\n",
      "\n",
      "블랙 위도우\n",
      "\n",
      "\n",
      "킬러의 보디가드 2\n",
      "\n",
      "\n",
      "루카\n",
      "\n",
      "\n",
      "제8일의 밤\n",
      "\n",
      "\n",
      "체르노빌 1986\n",
      "\n",
      "\n",
      "투모로우 워\n",
      "\n",
      "\n",
      "빛나는 순간\n",
      "\n",
      "\n",
      "괴기맨숀\n",
      "\n",
      "\n",
      "컨저링 3: 악마가 시켰다\n",
      "\n",
      "\n",
      "싱크홀\n",
      "\n",
      "\n",
      "기담\n",
      "\n",
      "\n",
      "아이스 로드\n",
      "\n",
      "\n",
      "열아홉\n",
      "\n",
      "\n",
      "캐시트럭\n",
      "\n",
      "\n",
      "분노의 질주: 더 얼티메이트\n",
      "\n",
      "\n",
      "다크 앤드 위키드\n",
      "\n",
      "\n",
      "모가디슈\n",
      "\n",
      "\n",
      "여고괴담 여섯번째 이야기 : 모교\n",
      "\n",
      "\n",
      "이보다 더 좋을 순 없다\n",
      "\n",
      "\n",
      "인질\n",
      "\n",
      "\n",
      "메이드 인 루프탑\n",
      "\n",
      "\n",
      "극장판 귀멸의 칼날: 무한열차편\n",
      "\n",
      "\n",
      "콰이어트 플레이스\n",
      "\n",
      "\n",
      "셔터\n",
      "\n",
      "\n",
      "뱅퀴시\n",
      "\n",
      "\n",
      "미션 임파서블: 루벤\n",
      "\n",
      "\n",
      "이스케이프 룸 2: 노 웨이 아웃\n",
      "\n",
      "\n",
      "웬디\n",
      "\n",
      "\n",
      "더 퍼지: 포에버\n",
      "\n",
      "\n",
      "이번엔 잘 되겠지\n",
      "\n",
      "\n",
      "방법: 재차의\n",
      "\n",
      "\n",
      "보스 베이비 2\n",
      "\n",
      "\n",
      "블라이스 스피릿\n",
      "\n",
      "\n",
      "더 수어사이드 스쿼드\n",
      "\n",
      "\n",
      "북샵\n",
      "\n",
      "\n",
      "우리는 매일매일\n",
      "\n",
      "\n",
      "혼자 사는 사람들\n",
      "\n",
      "\n",
      "오필리아\n",
      "\n",
      "\n",
      "시카다 3301\n",
      "\n",
      "\n",
      "샤크 : 더 비기닝\n",
      "\n",
      "\n",
      "한산: 용의 출현\n",
      "\n",
      "\n",
      "스페이스 잼: 새로운 시대\n",
      "\n",
      "\n",
      "그린 북\n",
      "\n",
      "\n",
      "트립 투 그리스\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 네이버 영화 랭킹 가져와서 전체 영화제목을 출력하세요.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "a = soup.select('td.title > div.tit3')\n",
    "\n",
    "for i in a:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "cb0ef7ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-4.6.3-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d7406c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ca_da\\anaconda\\envs\\cakd3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_tflow_select             2.3.0                     eigen  \n",
      "absl-py                   0.12.0           py38haa95532_0  \n",
      "aiohttp                   3.7.4            py38h2bbff1b_1  \n",
      "argon2-cffi               20.1.0           py38h2bbff1b_1  \n",
      "astor                     0.8.1            py38haa95532_0  \n",
      "astunparse                1.6.3                      py_0  \n",
      "async-timeout             3.0.1            py38haa95532_0  \n",
      "async_generator           1.10               pyhd3eb1b0_0  \n",
      "attrs                     21.2.0             pyhd3eb1b0_0  \n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \n",
      "beautifulsoup4            4.9.3                    pypi_0    pypi\n",
      "blas                      1.0                         mkl  \n",
      "bleach                    3.3.0              pyhd3eb1b0_0  \n",
      "blinker                   1.4              py38haa95532_0  \n",
      "brotlipy                  0.7.0           py38h2bbff1b_1003  \n",
      "bs4                       0.0.1                    pypi_0    pypi\n",
      "ca-certificates           2021.5.25            haa95532_1  \n",
      "cachetools                4.2.2              pyhd3eb1b0_0  \n",
      "certifi                   2021.5.30        py38haa95532_0  \n",
      "cffi                      1.14.5           py38hcd4344a_0  \n",
      "chardet                   3.0.4           py38haa95532_1003  \n",
      "click                     8.0.1              pyhd3eb1b0_0  \n",
      "colorama                  0.4.4              pyhd3eb1b0_0  \n",
      "coverage                  5.5              py38h2bbff1b_2  \n",
      "cryptography              3.4.7            py38h71e12ea_0  \n",
      "cycler                    0.10.0                   py38_0  \n",
      "cython                    0.29.23          py38hd77b12b_0  \n",
      "decorator                 5.0.9              pyhd3eb1b0_0  \n",
      "defusedxml                0.7.1              pyhd3eb1b0_0  \n",
      "entrypoints               0.3                      py38_0  \n",
      "freetype                  2.10.4               hd328e21_0  \n",
      "gast                      0.4.0                      py_0  \n",
      "google-auth               1.31.0             pyhd3eb1b0_0  \n",
      "google-auth-oauthlib      0.4.4              pyhd3eb1b0_0  \n",
      "google-pasta              0.2.0                      py_0  \n",
      "grpcio                    1.36.1           py38hc60d5dd_1  \n",
      "h5py                      2.10.0           py38h5e291fa_0  \n",
      "hdf5                      1.10.4               h7ebc959_0  \n",
      "icc_rt                    2019.0.0             h0cc432a_1  \n",
      "icu                       58.2                 ha925a31_3  \n",
      "idna                      2.10               pyhd3eb1b0_0  \n",
      "importlib-metadata        3.10.0           py38haa95532_0  \n",
      "importlib_metadata        3.10.0               hd3eb1b0_0  \n",
      "intel-openmp              2021.2.0           haa95532_616  \n",
      "ipykernel                 5.3.4            py38h5ca1d4c_0  \n",
      "ipython                   7.22.0           py38hd4e2768_0  \n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \n",
      "ipywidgets                7.6.3              pyhd3eb1b0_1  \n",
      "jedi                      0.17.0                   py38_0  \n",
      "jinja2                    3.0.0              pyhd3eb1b0_0  \n",
      "joblib                    1.0.1              pyhd3eb1b0_0  \n",
      "jpeg                      9b                   hb83a4c4_2  \n",
      "jsonschema                3.2.0                      py_2  \n",
      "jupyter                   1.0.0                    py38_7  \n",
      "jupyter_client            6.1.12             pyhd3eb1b0_0  \n",
      "jupyter_console           6.4.0              pyhd3eb1b0_0  \n",
      "jupyter_core              4.7.1            py38haa95532_0  \n",
      "jupyterlab_pygments       0.1.2                      py_0  \n",
      "jupyterlab_widgets        1.0.0              pyhd3eb1b0_1  \n",
      "keras                     2.4.3                         0  \n",
      "keras-applications        1.0.8                      py_1  \n",
      "keras-base                2.4.3                      py_0  \n",
      "keras-preprocessing       1.1.2              pyhd3eb1b0_0  \n",
      "kiwisolver                1.3.1            py38hd77b12b_0  \n",
      "libpng                    1.6.37               h2a8f88b_0  \n",
      "libprotobuf               3.14.0               h23ce68f_0  \n",
      "libsodium                 1.0.18               h62dcd97_0  \n",
      "libtiff                   4.2.0                hd0e1b90_0  \n",
      "lxml                      4.6.3                    pypi_0    pypi\n",
      "lz4-c                     1.9.3                h2bbff1b_0  \n",
      "m2w64-gcc-libgfortran     5.3.0                         6  \n",
      "m2w64-gcc-libs            5.3.0                         7  \n",
      "m2w64-gcc-libs-core       5.3.0                         7  \n",
      "m2w64-gmp                 6.1.0                         2  \n",
      "m2w64-libwinpthread-git   5.0.0.4634.697f757               2  \n",
      "markdown                  3.3.4            py38haa95532_0  \n",
      "markupsafe                2.0.1            py38h2bbff1b_0  \n",
      "matplotlib                3.3.4            py38haa95532_0  \n",
      "matplotlib-base           3.3.4            py38h49ac443_0  \n",
      "mistune                   0.8.4           py38he774522_1000  \n",
      "mkl                       2021.2.0           haa95532_296  \n",
      "mkl-service               2.3.0            py38h2bbff1b_1  \n",
      "mkl_fft                   1.3.0            py38h277e83a_2  \n",
      "mkl_random                1.2.1            py38hf11a4ad_2  \n",
      "msys2-conda-epoch         20160418                      1  \n",
      "multidict                 5.1.0            py38h2bbff1b_2  \n",
      "nbclient                  0.5.3              pyhd3eb1b0_0  \n",
      "nbconvert                 6.0.7                    py38_0  \n",
      "nbformat                  5.1.3              pyhd3eb1b0_0  \n",
      "nest-asyncio              1.5.1              pyhd3eb1b0_0  \n",
      "notebook                  6.4.0            py38haa95532_0  \n",
      "numpy                     1.20.2           py38ha4e8547_0  \n",
      "numpy-base                1.20.2           py38hc2deb75_0  \n",
      "oauthlib                  3.1.0                      py_0  \n",
      "olefile                   0.46                       py_0  \n",
      "openssl                   1.1.1k               h2bbff1b_0  \n",
      "opt_einsum                3.3.0              pyhd3eb1b0_1  \n",
      "packaging                 20.9               pyhd3eb1b0_0  \n",
      "pandas                    1.2.4            py38hd77b12b_0  \n",
      "pandoc                    2.12                 haa95532_0  \n",
      "pandocfilters             1.4.3            py38haa95532_1  \n",
      "parso                     0.8.2              pyhd3eb1b0_0  \n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
      "pillow                    8.2.0            py38h4fa10fc_0  \n",
      "pip                       21.1.2           py38haa95532_0  \n",
      "prometheus_client         0.11.0             pyhd3eb1b0_0  \n",
      "prompt-toolkit            3.0.17             pyh06a4308_0  \n",
      "prompt_toolkit            3.0.17               hd3eb1b0_0  \n",
      "protobuf                  3.14.0           py38hd77b12b_1  \n",
      "pyasn1                    0.4.8                      py_0  \n",
      "pyasn1-modules            0.2.8                      py_0  \n",
      "pycparser                 2.20                       py_2  \n",
      "pygments                  2.9.0              pyhd3eb1b0_0  \n",
      "pyjwt                     1.7.1                    py38_0  \n",
      "pyopenssl                 20.0.1             pyhd3eb1b0_1  \n",
      "pyparsing                 2.4.7              pyhd3eb1b0_0  \n",
      "pyqt                      5.9.2            py38ha925a31_4  \n",
      "pyreadline                2.1                      py38_1  \n",
      "pyrsistent                0.17.3           py38he774522_0  \n",
      "pysocks                   1.7.1            py38haa95532_0  \n",
      "python                    3.8.10               hdbf39b2_7  \n",
      "python-dateutil           2.8.1              pyhd3eb1b0_0  \n",
      "pytz                      2021.1             pyhd3eb1b0_0  \n",
      "pywin32                   227              py38he774522_1  \n",
      "pywinpty                  0.5.7                    py38_0  \n",
      "pyyaml                    5.4.1            py38h2bbff1b_1  \n",
      "pyzmq                     20.0.0           py38hd77b12b_1  \n",
      "qt                        5.9.7            vc14h73c81de_0  \n",
      "qtconsole                 5.1.0              pyhd3eb1b0_0  \n",
      "qtpy                      1.9.0                      py_0  \n",
      "requests                  2.25.1             pyhd3eb1b0_0  \n",
      "requests-oauthlib         1.3.0                      py_0  \n",
      "rsa                       4.7.2              pyhd3eb1b0_1  \n",
      "scikit-learn              0.24.2           py38hf11a4ad_1  \n",
      "scipy                     1.6.2            py38h66253e8_1  \n",
      "seaborn                   0.11.1             pyhd3eb1b0_0  \n",
      "send2trash                1.5.0              pyhd3eb1b0_1  \n",
      "setuptools                52.0.0           py38haa95532_0  \n",
      "sip                       4.19.13          py38ha925a31_0  \n",
      "six                       1.16.0             pyhd3eb1b0_0  \n",
      "soupsieve                 2.2.1                    pypi_0    pypi\n",
      "sqlite                    3.35.4               h2bbff1b_0  \n",
      "tensorboard               2.4.0              pyhc547734_0  \n",
      "tensorboard-plugin-wit    1.6.0                      py_0  \n",
      "tensorflow                2.3.0           mkl_py38h8c0d9a2_0  \n",
      "tensorflow-base           2.3.0           eigen_py38h75a453f_0  \n",
      "tensorflow-estimator      2.5.0              pyh7b7c402_0  \n",
      "termcolor                 1.1.0            py38haa95532_1  \n",
      "terminado                 0.9.4            py38haa95532_0  \n",
      "testpath                  0.4.4              pyhd3eb1b0_0  \n",
      "threadpoolctl             2.1.0              pyh5ca1d4c_0  \n",
      "tk                        8.6.10               he774522_0  \n",
      "tornado                   6.1              py38h2bbff1b_0  \n",
      "traitlets                 5.0.5              pyhd3eb1b0_0  \n",
      "typing-extensions         3.7.4.3              hd3eb1b0_0  \n",
      "typing_extensions         3.7.4.3            pyh06a4308_0  \n",
      "urllib3                   1.26.4             pyhd3eb1b0_0  \n",
      "vc                        14.2                 h21ff451_1  \n",
      "vs2015_runtime            14.27.29016          h5e58377_2  \n",
      "wcwidth                   0.2.5                      py_0  \n",
      "webencodings              0.5.1                    py38_1  \n",
      "werkzeug                  1.0.1              pyhd3eb1b0_0  \n",
      "wheel                     0.36.2             pyhd3eb1b0_0  \n",
      "widgetsnbextension        3.5.1                    py38_0  \n",
      "win_inet_pton             1.1.0            py38haa95532_0  \n",
      "wincertstore              0.2                      py38_0  \n",
      "winpty                    0.4.3                         4  \n",
      "wrapt                     1.12.1           py38he774522_1  \n",
      "xz                        5.2.5                h62dcd97_0  \n",
      "yaml                      0.2.5                he774522_0  \n",
      "yarl                      1.6.3            py38h2bbff1b_0  \n",
      "zeromq                    4.3.3                ha925a31_3  \n",
      "zipp                      3.4.1              pyhd3eb1b0_0  \n",
      "zlib                      1.2.11               h62dcd97_4  \n",
      "zstd                      1.4.9                h19a0ad4_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de22191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "req = requests.get('https://naver.com')\n",
    "html = req.text\n",
    "soup = bs(html,'lxml')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
