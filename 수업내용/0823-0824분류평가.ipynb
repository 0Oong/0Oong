{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 분류평가\n",
    "- TP, FP, FN, TN는 예측 클래스와 실제 클래스의 Positive 결정 값과 Negative 결정 값의 결합에 따라 결정\n",
    "- 앞문자 TruelFalse는 예측값과 실제 값이 같은가 틀린가를 의미하고 뒤 문자 Negative/Positive는 예측 결과 값이 부정 긍정을 의미\n",
    "- TN는 예측값을 Negative 값 0으로 예측했고 실제값 역시 Negative 값 이\n",
    "- FP는 예측값을 Positive 값 1로 예측했고 실제 값은 Negative 값 이\n",
    "- FN은 예측값을 Negative 값 0으로 예측했고 실제 값은 Positive 값 1\n",
    "- TP는 예측값을 Positive 값 1로 예측했고 실제값 역시 Positive 값 1\n",
    "- 정확도 = (TP + TN) / ( TP + TN + FP + FN)\n",
    "- 정밀도 = TP / ( TP + FP)\n",
    "- 재현율 = TPI (TP + FN)  *정밀도가 높으면 재현율이 낮아지는데 한쪽으로 치우쳐지지 않게 해야함\n",
    "- F1 = 2 * ( 정밀도 * 재현을) / (정밀도 + 재현율) : 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼때 높아짐. threshold를 조정해서 비율조정\n",
    "- 정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표\n",
    "- 재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우(ex. 보험사기, 암진단)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 정밀도 / 재현을 트레이드 오프\n",
    "- 정밀도 또는 재현율이 특별히 강조돼야 할 경우 분류의 결정 임곗값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있음\n",
    "- 정밀도와 재현율은 한쪽을 높이면 다른 하나의 수치는 낮아지므로 트레이드오프(Trade-off)관계임\n",
    "\n",
    "## 예측 확률을 반환하는 predict_proba()\n",
    "- 사이킷런 분류 알고리즘은 예측 데이터가 특정 레이블(결정 클래스 값)에 속하는지를 계산하기 위해 먼저 개별 레이블별로 결정 확률을 구함\n",
    "- 그리고 예측 확률이 큰 레이블 값으로 예측\n",
    "- 이진 분류 모델에서 특정 데이터가 0이 될 확률이 10%, 1이 될 확률이 90%로 예측되었다면 최종 예측은 더 큰 확률을 가진 1로 예측\n",
    "- 이진 분류에서는 이 임곗값을 0.5로 정하고 이 기준 값보다 확률이 크면 positive, 작으면 negative로 결정함\n",
    "- 사이킷런은 객별 데이터별로 예측 확률을 반환하는 메서드인 predict_prob()를 제공 - 학습이 완료된 사이킷런 Classifier 객체에서 호출\n",
    "- predict() 메서드와 유사하지만 단지 반환 결과가 예측 결과 클래스값이 아닌 예측 확률 결과임."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pandas as pd\n",
    "titanic_df = pd.read_csv('/Users/joy/Documents/GitHub/0Oong/수업내용/dataset/train.csv')\n",
    "titanic_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 일괄 전처리 사용자 함수(null 처리, 불필요 칼럼 삭제, 레이블 인코딩) \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "# Age(평균), Cabin('N'), Embarked('N'), Fare(0)\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "# PassengerId, Name, Ticket(티켓번호)\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행.\n",
    "# Cabin(선실번호 첫문자만 추출 후 인코딩), Sex(성별), Embarked(중간 정착 항구)\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 과제 \n",
    "# 6개 알고리즘 적용, 학습/예측/평가를 수행\n",
    "# KNN, 서포트백터머신, 렌덤포레스트, decision tree, GBM, logistic Regression\n",
    "\n",
    "# 6개 알고리즘에 대한 요약\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titainc_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titainc_df = transform_features(X_titainc_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titainc_df, y_titanic_df,\n",
    "test_size = 0.2, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred=lr_clf.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, pred)\n",
    "accuracy_lr"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8491620111731844"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test) \n",
    "pred = lr_clf.predict(X_test)\n",
    "print(type(pred_proba[:3]))\n",
    "print(pred.reshape(-1,1)[:3]) # 얘랑 마지막줄애랑 비교해서 보기 pred랑 pred_proba\n",
    "print()\n",
    "print(pred_proba[:3])\n",
    "\n",
    "# 모든 행별로 1이 될지 0이될지를 나타내주는 거라고 생각하면 된다. "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "[[0.46200919 0.53799081]\n",
      " [0.87869718 0.12130282]\n",
      " [0.8771684  0.1228316 ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "정리하자면 pred, pred_proba는 0이냐 1이냐를 구분해주는걸 보여주기 때문에 독립변수랑 종속변수(타이타닉에선 survived)를 분리해야만 사용할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1,-1,2],\n",
    "    [2,0,0],\n",
    "    [0,1.1,1.2]]\n",
    "\n",
    "binarizer =  Binarizer(threshold=1.1)  #binarizer는 threshold를 지정해서 기준값 보다 같거나 작으면 0, 크면 1을 반환한다. \n",
    "# (원래 pred_proba의 기본은 0.5를 기준으로 값 반환)\n",
    "\n",
    "print(binarizer.fit_transform(X))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "custom_threshold = 0.5\n",
    "print('pred_proba : \\n', pred_proba[:5])\n",
    "print()\n",
    "# 생존 확률 추출 후 2차원 배열로 변환\n",
    "# pred_proba = lr_clf.predict_proba(X_test) \n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "print('생존확률 : \\n', pred_proba_1[:5])\n",
    "print()\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "custom_predict[:5]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pred_proba : \n",
      " [[0.46200919 0.53799081]\n",
      " [0.87869718 0.12130282]\n",
      " [0.8771684  0.1228316 ]\n",
      " [0.88258534 0.11741466]\n",
      " [0.85519904 0.14480096]]\n",
      "\n",
      "생존확률 : \n",
      " [[0.53799081]\n",
      " [0.12130282]\n",
      " [0.1228316 ]\n",
      " [0.11741466]\n",
      " [0.14480096]]\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# get_clf_eval 평가 사용자 정의 함수\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred) \n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 : {:.4f}, 정밀도 : {:.4f}, 재현율 : {:.4f}, f1:{:.4f}'. format(accuracy, precision, recall, f1))\n",
    "get_clf_eval(y_test, custom_predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492, 정밀도 : 0.7742, 재현율 : 0.7869, f1:0.7805\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# 정확도 = (TP + TN) / ( TP + TN + FP + FN)\n",
    "# 정밀도 = TP / ( TP + FP)\n",
    "# 재현율 = TP / (TP + FN)\n",
    "# F1 = 2 * ( 정밀도 * 재현을) / (정밀도 + 재현율)\n",
    "\n",
    "a = 48 / (48 + 14)\n",
    "b = 48 / (48 + 13)\n",
    "print('정확도 :', (48 + 104) / (104 + 14 + 13 + 48))\n",
    "print('정밀도 :', 48 / (48 + 14))\n",
    "print('재현율 :', 48 / (48 + 13))\n",
    "print('F1 : ', ((a * b) / (a+b))*2)\n",
    "\n",
    "# TN FP\n",
    "# FN TP 155페이지 참고"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "정확도 : 0.8491620111731844\n",
      "정밀도 : 0.7741935483870968\n",
      "재현율 : 0.7868852459016393\n",
      "F1 :  0.7804878048780488\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import numpy as np\n",
    "Label = np.unique([y_test, pred])\n",
    "confustion_matrix = pd.DataFrame(\n",
    "    confusion_matrix(y_test, pred, labels=Label), \n",
    "    index=['true:{:}'.format(x) for x in Label], \n",
    "    columns=['pred:{:}'.format(x) for x in Label])\n",
    "print(confustion_matrix)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        pred:0  pred:1\n",
      "true:0     104      14\n",
      "true:1      13      48\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "Label = np.unique([y_test, pred])\n",
    "Label"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "# 객체 내의 값을 차례로 iteration 하면서 evaluation 수행\n",
    "\n",
    "    for custom_threshold in thresholds : \n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임계값', custom_threshold)\n",
    "        get_clf_eval(y_test,custom_predict)\n",
    "        print()\n",
    "\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "임계값 0.4\n",
      "오차행렬\n",
      "[[98 20]\n",
      " [10 51]]\n",
      "정확도 : 0.8324, 정밀도 : 0.7183, 재현율 : 0.8361, f1:0.7727\n",
      "\n",
      "임계값 0.45\n",
      "오차행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도 : 0.8492, 정밀도 : 0.7656, 재현율 : 0.8033, f1:0.7840\n",
      "\n",
      "임계값 0.5\n",
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492, 정밀도 : 0.7742, 재현율 : 0.7869, f1:0.7805\n",
      "\n",
      "임계값 0.55\n",
      "오차행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도 : 0.8659, 정밀도 : 0.8364, 재현율 : 0.7541, f1:0.7931\n",
      "\n",
      "임계값 0.6\n",
      "오차행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도 : 0.8771, 정밀도 : 0.8824, 재현율 : 0.7377, f1:0.8036\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 결과해석\n",
    "- 임계값이 낮을수록 많은 수의 양성 예측으로 인해 재현율 값이 극도로 높아지고 정밀도 값이 낲아짐.(FN이 작아지고 FP가 커짐)\n",
    "- 로지스틱 회귀 기반의 타이타닉 생존자 예측 모델의 경우 임계값이 약 0.5 지점에서 재현율과 정밀도가 비슷해지는 모습을 보인다.\n",
    "- 단순희 하나의 성능 지표 수치를 높이기 위한 수단으로 사용하는 것은 지양하고 업무 환경에 맞게 두 개의 수치를 상호 보완할 수 있는 수준에서 적용\n",
    "\n",
    "### 정밀도 및 재현율 활용시 유의 사항\n",
    "- 정밀도와 재현율 성능 수치는 어느 한쪽만 참조하는 극단적인 수치 조작이 가능\n",
    "- 정밀도 100%가 되는 방법 : 확실한 기준이 되는 경우만 Positive로 예측하고 나머지는 모두 Negative로 예측 전체 환자 1000명중 확실한 Positive 징후만 가진 환자는 단 1명이라고 하면 이 한명만 P로 예측하고 나머지느느 모두 N으로 예측 FP는 0, TP는 1이 되면 정밀도(TP/(TP+FP))는 30/(30+0)=1\n",
    "- 분류가 정밀도, 재현율 중 하나에 상대적인 중요도를 부여할 수 있지만 하나만 강조해서는 안됨\n",
    "- 암 예측 모델에서 재현율을 높인다고 주로 양성만 판정한다면 환자의 부담과 불평이 커지게 됨"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROC, AUC 커브\n",
    "- ROC : 수신자 판단 곡선이라고 하며, ML의 이진 분류 모델의 예측 성능을 판단하는 중요한 평가 지표\n",
    "- FRR이 변한 때, TPR이 어떻게 변하는지를 나타내는 곡선으로 FPR은 1-특이성(TNR), TPR은 재현율(민감도)를 나타냄.\n",
    "- TNR(특이성, 실제음성인데 음성을 맞춤)은 TN/(TN+FP)이며 FPR은 FP/(TN+FP)임\n",
    "- ROC 곡선은 FPR 곡선을 0부터 1까지 변경하면서 FPR을 구하고 이 FPR값의 변화에 따른 TPR변화 값을 구함.\n",
    "- FPR을 0에서 1까지 변경하는 것은 Positive 예측값을 결정하는 기준인 분류 결정 임곗값을 변경하면 됨.\n",
    "- FPR을 0으로 만들려면 임곗값을 1로 지정하고 반대로 FPR을 1로 만들려면 임곗값을 0으로 지정하면 됨."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titainc_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titainc_df = transform_features(X_titainc_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titainc_df, y_titanic_df,\n",
    "test_size = 0.2, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred=lr_clf.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, pred)\n",
    "accuracy_lr"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8491620111731844"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- True Positive Rate(TPR): True Positive/positive\n",
    "- False Positive Rate(FPR): False Positive /Negative\n",
    "- False Negative Rate(FNR): False Negative/Positive\n",
    "- True Negative Rate(TNR): True Negative/Negative"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# 이게 뭘 의미하는지 찬찬히 뜯어보기..이해하지 못했음 ..;;\n",
    "from sklearn.metrics import roc_curve\n",
    "pred_proba_c1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "thr_index = np.arange(1,thresholds.shape[0],5)\n",
    "thr_index\n",
    "print(np.round(thresholds[thr_index], 2))\n",
    "print(np.round(fprs[thr_index], 2))\n",
    "print(np.round(tprs[thr_index],2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.97 0.65 0.63 0.56 0.45 0.4  0.35 0.15 0.13 0.11 0.11]\n",
      "[0.   0.02 0.03 0.08 0.13 0.17 0.2  0.47 0.58 0.69 0.8 ]\n",
      "[0.03 0.64 0.72 0.75 0.8  0.84 0.89 0.9  0.93 0.97 0.98]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def roc_curve_plot(y_test, pred_porba_c1) :\n",
    "    fprs,tprs, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "    plt.plot(fprs, tprs, label='ROC')\n",
    "    plt.plot([0,1],[0,1], 'k--', label='Random')\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('FPR(1-specificity')\n",
    "    plt.ylabel('TPR(Recall)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "roc_curve_plot(y_test,lr_clf.predict_proba(X_test)[:,1])\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)  #roc_curve에서는 pred가 아니라 pred_proba를 넣어줘야 함 \n",
    "print('ROC AUC 값 : {:.4f}'.format(roc_score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROC AUC 값 : 0.9024\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred, pred_proba):\n",
    "    confusion = confusion_matrix(y_test, pred) \n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 : {:.4f}, 정밀도 : {:.4f}, 재현율 : {:.4f}, f1:{:.4f}, acu:{:.4f}'. format(accuracy, precision, recall, f1, roc_auc))\n",
    "get_clf_eval(y_test, pred, pred_proba) #pred는 위에서 찾아보셈"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492, 정밀도 : 0.7742, 재현율 : 0.7869, f1:0.7805, acu:0.9024\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 과제 \n",
    "### Q. 분류기는 Decision Tree(DT), parameters, cv=5, scoring ='accuracy'를 적용하여 교차검증과 성능 개선을 위한 하이퍼파라미터 튜닝을 수행하여 최적의 모델을 생성한 후 평가하세요. 평가는 분류 평가지표 모두를 포함하는 사용자 함수를 작성하여 수행\n",
    "[파라미터]\n",
    "- max_depth :[2,3,5,10]\n",
    "- min_samples_split : [2,3,5]\n",
    "- mean_samples_leaf : [1,5,8]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth' :[2,3,5,10], \n",
    "            'min_samples_split' : [2,3,5], \n",
    "            'min_samples_leaf' : [1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, cv=5, scoring='accuracy', refit=True) #최적의 하이퍼파라미터를 적용해서 다시 돌려줌\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print('최적의 하이퍼 파라미터 : \\n', grid_dclf.best_params_)\n",
    "print('최고 예측 정확도 : {0:.4f}'.format(grid_dclf.best_score_))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "최적의 하이퍼 파라미터 : \n",
      " {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "최고 예측 정확도 : 0.7992\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf=GradientBoostingClassifier(random_state=0)\n",
    "params = {\n",
    "    'n_estimators' : [100,200],\n",
    "    'learning_rate' : [0.05,0.1]    \n",
    "}\n",
    "  ## hyper parameter vs  parameter\n",
    "     # hyper -> 직접 입력해주는 값이 hyper parameter (n_estimators , learning_rate)\n",
    "        \n",
    "     #  parameter --> 직접 안 입력해도되는거 ex: 계수 , 절편\n",
    "start_time = time.time()\n",
    "grid_cv = GridSearchCV(gb_clf,param_grid = params,cv=2,verbose=1)\n",
    "grid_cv.fit(X_train,y_train)\n",
    "print('최적 하이퍼 파라미터:\\n',grid_cv.best_params_)\n",
    "print('최고 예측 정확도:{:.4f}'.format(grid_cv.best_score_))\n",
    "\n",
    "print('수행시간 : {0:1f} 초'.format(time.time()-start_time))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "최고 예측 정확도:0.8146\n",
      "수행시간 : 1.295468 초\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,\n",
    "                                                   test_size=0.2, random_state=11)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train,y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test,pred)\n",
    "accuracy_dt"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#  GridSearchCV : 교차검증과 성능 개선을 위한 하이퍼파라미터 튜닝을 동시에 수행\n",
    "# 교차 검증을 기반으로 하이퍼 파라미터의 최적 값을 찾게 해줌\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score , \\\n",
    "recall_score ,confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5],\\\n",
    "              'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', \\\n",
    "                         cv=5, refit=True)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "print(grid_dclf)\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_dclf.best_params_)\n",
    "print('GridSeachCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "print(best_dclf)\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "dpred_proba = best_dclf.predict_proba(X_test)[:,1]\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print('grid_dt 예측 정확도 :', accuracy)\n",
    "\n",
    "def get_clf_eval(y_test , dpredictions, dpred_proba):\n",
    "    confusion = confusion_matrix( y_test, dpredictions)\n",
    "    accuracy = accuracy_score(y_test , dpredictions)\n",
    "    precision = precision_score(y_test , dpredictions)\n",
    "    recall = recall_score(y_test , dpredictions)\n",
    "    f1 = f1_score(y_test,dpredictions)\n",
    "    roc_auc = roc_auc_score(y_test, dpred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print()    \n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "get_clf_eval(y_test , dpredictions, dpred_proba)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [2, 3, 5, 10],\n",
      "                         'min_samples_leaf': [1, 5, 8],\n",
      "                         'min_samples_split': [2, 3, 5]},\n",
      "             scoring='accuracy')\n",
      "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSeachCV 최고 정확도: 0.7992\n",
      "DecisionTreeClassifier(max_depth=3, min_samples_leaf=5)\n",
      "grid_dt 예측 정확도 : 0.8715083798882681\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 14  47]]\n",
      "\n",
      "정확도: 0.8715, 정밀도: 0.8393, 재현율: 0.7705,    F1: 0.8034, AUC:0.8937\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}